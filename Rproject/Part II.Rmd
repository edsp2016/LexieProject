---
title: 'Part II: Modeling and conclusion'
author: "Siyang Sun"
date: "May 10, 2016"
output: html_document
---
My whole data set after cleaning is stored in the data-file folder, called "all data". For modeling part, some of the columns are meaningless. So I used the subset of whole data set for modeling, which is called "modeling" in the same folder. Feel free to use that dataset if you just want to go through the modeling part.
# Modeling
```{r}
da<-read.table("/Users/mac/Dropbox/EDSP/modeling.txt",header=T)
da$adjusted.1<-NULL
summary(da)
#theater,adow,rn,to_rating
```
Variables including theater, number of reviews and rating (rotten tomatoes), opening weekend have more than 20% missing values,drop them from regression models.
## Part 1: Linear regression models
### 1.Variable selection startegy
First check the correlation between variables. Highly correlated variables could result in collinearity. The correlation coefficients results are stored in corr_table2; it turns out that the award data(times of winning and nomitation) are highly correlated. 
Second check the skewness and make some variables transformation. 
I use log transformation on variables including: adjusted,adow,bb and all movie award data, and stored them as new variables.
```{r}
library(ggplot2)
corr_table2<-round(cor(subset(na.omit(da),select=c(adjusted,adow,adbudget,theater,bb,rating,to_rating,rn,runt,dir_win,dir_nomi,st1_win,st1_nomi,st2_win,st2_nomi))),2)
ggplot(melt(corr_table2), aes(x=Var1, y=Var2, fill=value))+geom_tile()
#movie awards data have high correlation,collinearity should be considered.
#variable transformation
#normal variables: rating,runt
da$logadjusted<-log(da$adjusted)
qplot(da$adjusted, geom="histogram",stat="count")
qplot(da$logadjusted, geom="histogram",stat="count")
da$logadow<-log(da$adow)
da$logbb<-log(da$bb)
da$lgadbug<-log(da$adbudget)
da$lgdir_win<-log(da$dir_win)
da$lgdir_nomi<-log(da$dir_nomi)
da$lgst1_win<-log(da$st1_win)
da$lgst1_nomi<-log(da$st1_nomi)
da$lgst2_win<-log(da$st2_win)
da$lgst2_nomi<-log(da$st2_nomi)
da$lgdir_win<-gsub("-Inf","NA",da$lgdir_win)
da$lgdir_nomi<-gsub("-Inf","NA",da$lgdir_nomi)
da$lgst1_win<-gsub("-Inf","NA",da$lgst1_win)
da$lgst1_nomi<-gsub("-Inf","NA",da$lgst1_nomi)
da$lgst2_win<-gsub("-Inf","NA",da$lgst2_win)
da$lgst2_nomi<-gsub("-Inf","NA",da$lgst2_nomi)
da$lgdir_win<-as.numeric(da$lgdir_win)
da$lgdir_nomi<-as.numeric(da$lgdir_nomi)
da$lgst1_win<-as.numeric(da$lgst1_win)
da$lgst1_nomi<-as.numeric(da$lgst1_nomi)
da$lgst2_win<-as.numeric(da$lgst2_win)
da$lgst2_nomi<-as.numeric(da$lgst2_nomi)
#adbudget theater to_rating rn still have skewness after log transformation.
```
### 2. baseline model
```{r}
#all potentialdependent variables:logadjusted,logbb
#all potential independent variables:studio+release_year+genre1+mpaa+rating+runt+per+sh+series+lgadbug+lgdir_win+lgdir_nomi+lgst1_win+lgst1_nomi+lgst2_win+lgst2_nomi
res0<-lm(logadjusted~lgadbug,na.omit(da))
#summary(res0)
#lapply(da,class)
```
### 3. model selection
+ Case 1: Outcome variable: domestic box office (adjusted)
```{r}
resfull<-lm(logadjusted~studio+release_year+genre1+mpaa+rating+runt+per+sh+series+lgadbug+lgdir_win+lgdir_nomi+lgst1_win+lgst1_nomi+lgst2_win+lgst2_nomi,na.omit(da))
summary(resfull)
#adjusted R square 55.68%. AIC=89.36614
library(MASS)
step<-stepAIC(resfull,direction="backward")
res1<-lm(logadjusted~studio+release_year+genre1+rating+runt+per+factor(sh)+series+lgdir_win+lgdir_nomi+lgst2_nomi,na.omit(da))
#summary(res1)
#adjusted R^2 61.86% AIC=75.009 BIC=186.9145
n<-nrow(na.omit(da))
stepBIC<-step(resfull,direction = "both",k=log(n))
res1_1<-lm(logadjusted ~ release_year + rating + series + lgadbug,na.omit(da))
#summary(res1_1)
#R^2 33.14%, delete
```
+ Case 2: Outcome variable: domestic box office revenue/ movie budget (adjusted)
```{r}
resfull2<-lm(logbb~studio+release_year+genre1+mpaa+rating+runt+per+as.factor(sh)+series+lgdir_win+lgdir_nomi+lgst1_win+lgst1_nomi+lgst2_win+lgst2_nomi,na.omit(da))
#summary(resfull2)
#adjusted R square 55.41%.
step2<-stepAIC(resfull2,direction="backward")
res2<-lm(logbb~studio+release_year+genre1+mpaa+rating+runt+per+as.factor(sh)+lgdir_win+lgst1_win +lgst1_nomi,na.omit(da))
#summary(res2)
#adjusted R square 57% AIC=117.6126
```
### 4.variables transformation 
```{r}
da$dir<-log(0.75*da$dir_win+0.25*da$dir_nomi)
da$st1<-log(0.75*da$st1_win+0.25*da$st1_nomi)
da$st2<-log(0.75*da$st2_win+0.25*da$st2_nomi)
qplot(da$dir, geom="histogram",stat="count")
resnew<-lm(logadjusted~studio+release_year+genre1+mpaa+rating+runt+per+sh+series+lgadbug+dir+st1+st2,na.omit(da))
#summary(resnew)
# R^2 53.69% AIC 93.0
step3<-stepAIC(resnew,direction="backward")
res3<-lm(logadjusted ~ studio + release_year + genre1 + rating + runt + per + series + lgadbug,na.omit(da))
#summary(res3)
#R^2 55.97% AIC 86.20
resnew2<-lm(logbb~studio+release_year+genre1+mpaa+rating+runt+per+sh+series+dir+st1+st2,na.omit(da))
#summary(resnew2)
#52.2%
step4<-stepAIC(resnew2,direction="backward")
res4<-lm(logbb ~ studio + release_year + genre1 +mpaa+ rating + per+ dir,na.omit(da))
#summary(res4)
#55.43%,AIC=118.8446
```
What if we ignore the normality assumption and stop making log transformation?
```{r}
resfull3<-lm(adjusted~studio+release_year+genre1+mpaa+rating+runt+per+sh+series+lgadbug+dir_win+dir_nomi+st1_win+st1_nomi+st2_win+st2_nomi,na.omit(da))
step5<-stepAIC(resfull3,direction="backward")
res5<-lm(adjusted ~ studio + release_year + genre1 + rating + runt + per + 
    series + dir_win + dir_nomi + st2_win + st2_nomi,na.omit(da))
#summary(res5)
resfull4<-lm(bb~studio+release_year+genre1+mpaa+rating+runt+per+sh+series+dir_win+dir_nomi+st1_win+st1_nomi+st2_win+st2_nomi,na.omit(da))
step6<-stepAIC(resfull4,direction="backward")
res6<-lm(bb ~ studio + release_year + genre1 + mpaa + rating + runt,na.omit(da))
#summary(res6)
#42.08%,AIC=1182.888
```
### 5. conclusion
| Model name    |    Outcome   | Adjusted R^2|     AIC     |
|:-------------:|:------------:|:-----------:|:-----------:|
|      res1     |log(adjusted) |     61.86%  |   75.009    |
|      res2     |   log(bb)    |       57%   |     117     |
|      res3     |log(adjusted) |     55.97%  |    86.20    |
|      res4     |   log(bb)    |     55.43%  |   118.845   |
|      res5     |   adjusted   |     47.73%  |  1171.801   |
|      res6     |      bb      |     45.89%  |  308.9774   |
The first model has the highest adjusted R^2 and the smallest AIC, in this case I choose res 1.
The log adjusted domestic box office revenue is the outcome
```{r}
summary(res1)
layout(matrix(c(1,2,3,4),2,2))
plot(res1,cex=0.5)
```
The residual diagnostic seems fine.
From the model coefficients,
some variables including IMDb rating, non holiday seanson (ns&ss), series movie, director's times of winning awards show a significant positive effect on the box office. 
On the other hand,war movies or movies which is distributed by Par. show a significant negative effect on the box office. (at 0.01 significant level.)
## Part 2: Regression decision tree
Regression decision tree is better when facing some missing values. 
### necessary tree packages in R
```{r}
#regression decision tree
#install.packages("rpart")
#install.packages("tree")
#install.packages("rpart.plot")
library(rpart)
library(tree)
library(rpart.plot)
#cross validation
install.packages("caret")
install.packages("e1071")
library(caret)
library(e1071)
#random forest
```

```{r}
#rpart package
frmla<-bb~studio+release_year+genre1+mpaa+rating+runt+per+sh+series+rn+to_rating+dir_win+dir_nomi+st1_win+st1_nomi+st2_win+st2_nomi
frm2<-bb~studio+release_year+genre1+mpaa+rating+runt+per+sh+series+rn+to_rating+dir_win+dir_nomi+st1_win+st1_nomi+st2_win+st2_nomi
fit<-rpart(frmla,method="anova",data=da,minbucket=10)
printcp(fit)
par(mfrow=c(1,1))
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits
rpart.plot(fit)
plot(predict(fit),col="blue")
points(da$bb,col="red")
## cross validation
numFolds = trainControl(method="cv", number=5)
cpGrid = expand.grid(.cp = seq(0.01,0.5,0.01))
train(frmla, data=da , method="rpart", trControl=numFolds, tuneGrid = cpGrid)
train(frmla_tree, data=da,method="rpart", trControl=numFolds, tuneGrid = cpGrid)
#get the optimal cp and prune the tree
??
prediction??

```
## Part 3: Random Forest
packages
```{r}
#install.packages("randomForest")
library(randomForest)
```

```{r}
forestModel=randomForest(frmla,data=na.omit(da),ntree=20,importance=T)
vu = varUsed(forestModel, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(forestModel$forest$xlevels[vusorted$ix]))
varImpPlot(forestModel)
```








